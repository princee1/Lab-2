{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0__kU3yjxbh"
      },
      "source": [
        "# Application of ML-based algorithm on The TON_IoT Datasets\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNc9Mya2jxbj"
      },
      "source": [
        "## Library\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZUQ7tSkjxbj"
      },
      "outputs": [],
      "source": [
        "#!pip install torch scikit-learn pandas numpy prettyprint cupy tqdm matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Zs6Ea9q8jxbk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from typing import Literal, Callable\n",
        "import timeit\n",
        "from sklearn.metrics import roc_curve, precision_recall_curve, auc\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.decomposition import PCA\n",
        "from pprint import pprint\n",
        "from gc import collect\n",
        "from time import sleep\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#import cupy as cp\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from colorama import Fore, Back, Style\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExqII48-jxbk"
      },
      "source": [
        "## Loading the data set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4KpUUdMsjxbk"
      },
      "outputs": [],
      "source": [
        "TRAIN_DATASET = 'UNSW_NB15_training-set.csv'\n",
        "TEST_DATASET = 'UNSW_NB15_testing-set.csv'\n",
        "\n",
        "VALIDATION_FRAC = 0.35"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "u0640isSjxbl"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv(TRAIN_DATASET)\n",
        "df_test = pd.read_csv(TEST_DATASET)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "xcEqLoPzjxbl",
        "outputId": "84eac20e-8bee-45d8-854b-698530580e40"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>dur</th>\n",
              "      <th>proto</th>\n",
              "      <th>service</th>\n",
              "      <th>state</th>\n",
              "      <th>spkts</th>\n",
              "      <th>dpkts</th>\n",
              "      <th>sbytes</th>\n",
              "      <th>dbytes</th>\n",
              "      <th>rate</th>\n",
              "      <th>...</th>\n",
              "      <th>ct_dst_sport_ltm</th>\n",
              "      <th>ct_dst_src_ltm</th>\n",
              "      <th>is_ftp_login</th>\n",
              "      <th>ct_ftp_cmd</th>\n",
              "      <th>ct_flw_http_mthd</th>\n",
              "      <th>ct_src_ltm</th>\n",
              "      <th>ct_srv_dst</th>\n",
              "      <th>is_sm_ips_ports</th>\n",
              "      <th>attack_cat</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.121478</td>\n",
              "      <td>tcp</td>\n",
              "      <td>-</td>\n",
              "      <td>FIN</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>258</td>\n",
              "      <td>172</td>\n",
              "      <td>74.087490</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.649902</td>\n",
              "      <td>tcp</td>\n",
              "      <td>-</td>\n",
              "      <td>FIN</td>\n",
              "      <td>14</td>\n",
              "      <td>38</td>\n",
              "      <td>734</td>\n",
              "      <td>42014</td>\n",
              "      <td>78.473372</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1.623129</td>\n",
              "      <td>tcp</td>\n",
              "      <td>-</td>\n",
              "      <td>FIN</td>\n",
              "      <td>8</td>\n",
              "      <td>16</td>\n",
              "      <td>364</td>\n",
              "      <td>13186</td>\n",
              "      <td>14.170161</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1.681642</td>\n",
              "      <td>tcp</td>\n",
              "      <td>ftp</td>\n",
              "      <td>FIN</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>628</td>\n",
              "      <td>770</td>\n",
              "      <td>13.677108</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0.449454</td>\n",
              "      <td>tcp</td>\n",
              "      <td>-</td>\n",
              "      <td>FIN</td>\n",
              "      <td>10</td>\n",
              "      <td>6</td>\n",
              "      <td>534</td>\n",
              "      <td>268</td>\n",
              "      <td>33.373826</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>39</td>\n",
              "      <td>0</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 45 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   id       dur proto service state  spkts  dpkts  sbytes  dbytes       rate  \\\n",
              "0   1  0.121478   tcp       -   FIN      6      4     258     172  74.087490   \n",
              "1   2  0.649902   tcp       -   FIN     14     38     734   42014  78.473372   \n",
              "2   3  1.623129   tcp       -   FIN      8     16     364   13186  14.170161   \n",
              "3   4  1.681642   tcp     ftp   FIN     12     12     628     770  13.677108   \n",
              "4   5  0.449454   tcp       -   FIN     10      6     534     268  33.373826   \n",
              "\n",
              "   ...  ct_dst_sport_ltm  ct_dst_src_ltm  is_ftp_login  ct_ftp_cmd  \\\n",
              "0  ...                 1               1             0           0   \n",
              "1  ...                 1               2             0           0   \n",
              "2  ...                 1               3             0           0   \n",
              "3  ...                 1               3             1           1   \n",
              "4  ...                 1              40             0           0   \n",
              "\n",
              "   ct_flw_http_mthd  ct_src_ltm  ct_srv_dst  is_sm_ips_ports  attack_cat  \\\n",
              "0                 0           1           1                0      Normal   \n",
              "1                 0           1           6                0      Normal   \n",
              "2                 0           2           6                0      Normal   \n",
              "3                 0           2           1                0      Normal   \n",
              "4                 0           2          39                0      Normal   \n",
              "\n",
              "   label  \n",
              "0      0  \n",
              "1      0  \n",
              "2      0  \n",
              "3      0  \n",
              "4      0  \n",
              "\n",
              "[5 rows x 45 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "g-Z3xKd3jxbl"
      },
      "outputs": [],
      "source": [
        "def print_dataframe_shape(df:pd.DataFrame,name):print(f\"The shape of {name} is: {df.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIlvhVJGjxbl",
        "outputId": "bcfdcee7-4bf9-45b6-e93f-fd7d5ba59b32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The shape of Training Set is: (175341, 45)\n",
            "The shape of Testing Set is: (82332, 45)\n"
          ]
        }
      ],
      "source": [
        "print_dataframe_shape(df_train,'Training Set')\n",
        "print_dataframe_shape(df_test,'Testing Set')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Nd5FbxRzjxbm"
      },
      "outputs": [],
      "source": [
        "Features = Literal['dur',\n",
        " 'proto',\n",
        " 'service',\n",
        " 'state',\n",
        " 'spkts',\n",
        " 'dpkts',\n",
        " 'sbytes',\n",
        " 'dbytes',\n",
        " 'rate',\n",
        " 'sttl',\n",
        " 'dttl',\n",
        " 'sload',\n",
        " 'dload',\n",
        " 'sloss',\n",
        " 'dloss',\n",
        " 'sinpkt',\n",
        " 'dinpkt',\n",
        " 'sjit',\n",
        " 'djit',\n",
        " 'swin',\n",
        " 'stcpb',\n",
        " 'dtcpb',\n",
        " 'dwin',\n",
        " 'tcprtt',\n",
        " 'synack',\n",
        " 'ackdat',\n",
        " 'smean',\n",
        " 'dmean',\n",
        " 'trans_depth',\n",
        " 'response_body_len',\n",
        " 'ct_srv_src',\n",
        " 'ct_state_ttl',\n",
        " 'ct_dst_ltm',\n",
        " 'ct_src_dport_ltm',\n",
        " 'ct_dst_sport_ltm',\n",
        " 'ct_dst_src_ltm',\n",
        " 'is_ftp_login',\n",
        " 'ct_ftp_cmd',\n",
        " 'ct_flw_http_mthd',\n",
        " 'ct_src_ltm',\n",
        " 'ct_srv_dst',\n",
        " 'is_sm_ips_ports',\n",
        " 'label']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VC4ZL0Rvjxbm"
      },
      "source": [
        "### Understanding the data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "XMgSQ0pwjxbm"
      },
      "outputs": [],
      "source": [
        "y_label = 'label'\n",
        "features_list = df_train.columns.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "1ejQtlMRjxbm"
      },
      "outputs": [],
      "source": [
        "def separate(df:pd.DataFrame,):\n",
        "    features = features_list.copy()\n",
        "    features.remove(y_label)\n",
        "    return df.drop(y_label,axis=1),df[y_label]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sgrEx-xjxbm"
      },
      "source": [
        "## Preprocessing the Data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_Xn3Xsvjxbn"
      },
      "source": [
        "### Cleaning the Data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jM7Rf9YWjxbn"
      },
      "source": [
        "#### Helper Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "B4QhUwPjjxbn"
      },
      "outputs": [],
      "source": [
        "def standardize(df,column:Features):\n",
        "    col_values = df[column].values\n",
        "\n",
        "    mean = np.mean(col_values)\n",
        "    std = np.std(col_values)\n",
        "    col_values = col_values-mean\n",
        "    col_values= col_values/std\n",
        "    return pd.Series(col_values, name=column)\n",
        "\n",
        "\n",
        "def min_max_scaling(df, column:Features):\n",
        "    col_values = df[column].values\n",
        "    min_value = np.min(col_values)\n",
        "    max_value = np.max(col_values)\n",
        "    scaled_values = (col_values - min_value) / (max_value - min_value)\n",
        "    return pd.Series(scaled_values, name=column)\n",
        "\n",
        "def state_to_mask(state_vector: np.ndarray):\n",
        "    unique_val = np.unique(state_vector)\n",
        "    size = len(unique_val)\n",
        "    return { unique_val[mask]:mask for mask in range(size)}\n",
        "\n",
        "def one_hot_encoding(state_mask:dict[int,str]):\n",
        "    def wrapper(mask: str):\n",
        "        v = np.zeros((1, len(state_mask)))\n",
        "        mask = state_mask[mask]\n",
        "        v[0][mask] = 1\n",
        "        return v\n",
        "    return wrapper\n",
        "\n",
        "def one_hot_vector_distance(v1: np.ndarray, v2: np.ndarray):\n",
        "    if v1.shape != v2.shape:\n",
        "        raise\n",
        "    if np.array_equal(v1, v2):\n",
        "        return 0\n",
        "    return 1\n",
        "\n",
        "def str_encoder(df:pd.DataFrame,column:Features):\n",
        "    label_encoder = LabelEncoder()\n",
        "    df[column] = label_encoder.fit_transform(df[column])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "871uiKs3jxbn"
      },
      "outputs": [],
      "source": [
        "\n",
        "def remove_uncessaryFeature(df: pd.DataFrame, features: list = []):\n",
        "    try:\n",
        "        return df.drop(features, axis=1)\n",
        "    except KeyError :\n",
        "        return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZL-V05ujxbn"
      },
      "source": [
        "#### Cleaning Function ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "PVg2fiKfjxbn"
      },
      "outputs": [],
      "source": [
        "features_to_normalize=['dur','spkts','stcpb','dtcpb','dpkts','dbytes','sbytes',\n",
        "                       'rate',\n",
        "    'sload','dload','sloss','dloss','sinpkt','dinpkt','sjit','djit','tcprtt','synack','smean','dmean','response_body_len',]\n",
        "features_to_ohe=['proto','service','state','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd','ct_state_ttl']\n",
        "initial_features_to_remove = ['id','attack_cat']\n",
        "\n",
        "def preprocess_final(df:pd.DataFrame, normalize: Literal['min_max_scaling','standardize']=standardize,features_to_remove:list=[]):\n",
        "\n",
        "    ftr = set(features_to_remove)\n",
        "    df =remove_uncessaryFeature(df,[*initial_features_to_remove,*features_to_remove])\n",
        "    \n",
        "    for feature in set(features_to_ohe).difference(ftr):\n",
        "        #ohe_func = one_hot_encoding(state_to_mask(df[feature]))\n",
        "        str_encoder(df,feature)\n",
        "\n",
        "    for feature in set(features_to_normalize).difference(ftr):\n",
        "        df[feature] = normalize(df,feature)\n",
        "\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "jiZOONahjxbn"
      },
      "outputs": [],
      "source": [
        "\n",
        "text_featuresType = ['proto','service','state']\n",
        "def preprocess_partial(df:pd.DataFrame):\n",
        "\n",
        "    df =remove_uncessaryFeature(df,['label',*initial_features_to_remove])\n",
        "\n",
        "    for feature in text_featuresType:\n",
        "        str_encoder(df,feature)\n",
        "\n",
        "    for feature in features_to_normalize:\n",
        "        df[feature] = standardize(df,feature)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7r1kAqahjxbo"
      },
      "source": [
        "## Feature Selection\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2BJMgVyjxbo"
      },
      "source": [
        "##### Looking for the features that has highest impact\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "oSXWmW8ejxbo"
      },
      "outputs": [],
      "source": [
        "df_feature_analysis= preprocess_partial(df_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUOdvDPmjxbo"
      },
      "source": [
        "##### Correlation Matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "tyAMh_kmjxbo"
      },
      "outputs": [],
      "source": [
        "def find_highest_correlation(corr_matrix:pd.DataFrame, target_feature:str):\n",
        "    target_corr = corr_matrix[target_feature].drop(target_feature)\n",
        "    highest_corr_feature = target_corr.idxmax()\n",
        "    highest_corr_value = target_corr[highest_corr_feature]\n",
        "    \n",
        "    return highest_corr_feature, highest_corr_value\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "clmc2iCFjxbo",
        "outputId": "1082bdd2-4455-4831-88fa-08bf7a4f0c76"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dur</th>\n",
              "      <th>proto</th>\n",
              "      <th>service</th>\n",
              "      <th>state</th>\n",
              "      <th>spkts</th>\n",
              "      <th>dpkts</th>\n",
              "      <th>sbytes</th>\n",
              "      <th>dbytes</th>\n",
              "      <th>rate</th>\n",
              "      <th>sttl</th>\n",
              "      <th>...</th>\n",
              "      <th>ct_dst_ltm</th>\n",
              "      <th>ct_src_dport_ltm</th>\n",
              "      <th>ct_dst_sport_ltm</th>\n",
              "      <th>ct_dst_src_ltm</th>\n",
              "      <th>is_ftp_login</th>\n",
              "      <th>ct_ftp_cmd</th>\n",
              "      <th>ct_flw_http_mthd</th>\n",
              "      <th>ct_src_ltm</th>\n",
              "      <th>ct_srv_dst</th>\n",
              "      <th>is_sm_ips_ports</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>dur</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.124502</td>\n",
              "      <td>0.008234</td>\n",
              "      <td>0.103443</td>\n",
              "      <td>0.254559</td>\n",
              "      <td>0.181182</td>\n",
              "      <td>0.199731</td>\n",
              "      <td>0.144134</td>\n",
              "      <td>0.120966</td>\n",
              "      <td>0.012196</td>\n",
              "      <td>...</td>\n",
              "      <td>0.086300</td>\n",
              "      <td>0.094091</td>\n",
              "      <td>0.093923</td>\n",
              "      <td>0.101760</td>\n",
              "      <td>0.020641</td>\n",
              "      <td>0.020641</td>\n",
              "      <td>0.024743</td>\n",
              "      <td>0.080871</td>\n",
              "      <td>0.115336</td>\n",
              "      <td>0.035370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>proto</th>\n",
              "      <td>0.124502</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.170032</td>\n",
              "      <td>0.172441</td>\n",
              "      <td>0.013469</td>\n",
              "      <td>0.026439</td>\n",
              "      <td>0.005920</td>\n",
              "      <td>0.015812</td>\n",
              "      <td>0.013924</td>\n",
              "      <td>0.049944</td>\n",
              "      <td>...</td>\n",
              "      <td>0.191101</td>\n",
              "      <td>0.174965</td>\n",
              "      <td>0.165796</td>\n",
              "      <td>0.175708</td>\n",
              "      <td>0.018003</td>\n",
              "      <td>0.018003</td>\n",
              "      <td>0.028809</td>\n",
              "      <td>0.168121</td>\n",
              "      <td>0.198594</td>\n",
              "      <td>0.585941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>service</th>\n",
              "      <td>0.008234</td>\n",
              "      <td>0.170032</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.144978</td>\n",
              "      <td>0.114403</td>\n",
              "      <td>0.077338</td>\n",
              "      <td>0.105188</td>\n",
              "      <td>0.035492</td>\n",
              "      <td>0.141709</td>\n",
              "      <td>0.295302</td>\n",
              "      <td>...</td>\n",
              "      <td>0.047685</td>\n",
              "      <td>0.038347</td>\n",
              "      <td>0.051106</td>\n",
              "      <td>0.006774</td>\n",
              "      <td>0.071051</td>\n",
              "      <td>0.071051</td>\n",
              "      <td>0.266206</td>\n",
              "      <td>0.028599</td>\n",
              "      <td>0.048011</td>\n",
              "      <td>0.088847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>state</th>\n",
              "      <td>0.103443</td>\n",
              "      <td>0.172441</td>\n",
              "      <td>0.144978</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.078701</td>\n",
              "      <td>0.098268</td>\n",
              "      <td>0.049300</td>\n",
              "      <td>0.059759</td>\n",
              "      <td>0.432307</td>\n",
              "      <td>0.584697</td>\n",
              "      <td>...</td>\n",
              "      <td>0.328748</td>\n",
              "      <td>0.372309</td>\n",
              "      <td>0.408662</td>\n",
              "      <td>0.429906</td>\n",
              "      <td>0.051970</td>\n",
              "      <td>0.051970</td>\n",
              "      <td>0.078856</td>\n",
              "      <td>0.323019</td>\n",
              "      <td>0.387446</td>\n",
              "      <td>0.094198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>spkts</th>\n",
              "      <td>0.254559</td>\n",
              "      <td>0.013469</td>\n",
              "      <td>0.114403</td>\n",
              "      <td>0.078701</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.390067</td>\n",
              "      <td>0.963791</td>\n",
              "      <td>0.206609</td>\n",
              "      <td>0.076358</td>\n",
              "      <td>0.102723</td>\n",
              "      <td>...</td>\n",
              "      <td>0.060194</td>\n",
              "      <td>0.068373</td>\n",
              "      <td>0.072484</td>\n",
              "      <td>0.077553</td>\n",
              "      <td>0.009951</td>\n",
              "      <td>0.009951</td>\n",
              "      <td>0.006084</td>\n",
              "      <td>0.061584</td>\n",
              "      <td>0.069598</td>\n",
              "      <td>0.017770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dpkts</th>\n",
              "      <td>0.181182</td>\n",
              "      <td>0.026439</td>\n",
              "      <td>0.077338</td>\n",
              "      <td>0.098268</td>\n",
              "      <td>0.390067</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.188476</td>\n",
              "      <td>0.971907</td>\n",
              "      <td>0.098202</td>\n",
              "      <td>0.192580</td>\n",
              "      <td>...</td>\n",
              "      <td>0.071909</td>\n",
              "      <td>0.086695</td>\n",
              "      <td>0.094267</td>\n",
              "      <td>0.094085</td>\n",
              "      <td>0.013491</td>\n",
              "      <td>0.013491</td>\n",
              "      <td>0.047974</td>\n",
              "      <td>0.075190</td>\n",
              "      <td>0.078342</td>\n",
              "      <td>0.021765</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sbytes</th>\n",
              "      <td>0.199731</td>\n",
              "      <td>0.005920</td>\n",
              "      <td>0.105188</td>\n",
              "      <td>0.049300</td>\n",
              "      <td>0.963791</td>\n",
              "      <td>0.188476</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.009926</td>\n",
              "      <td>0.028468</td>\n",
              "      <td>0.020860</td>\n",
              "      <td>...</td>\n",
              "      <td>0.026661</td>\n",
              "      <td>0.026490</td>\n",
              "      <td>0.027281</td>\n",
              "      <td>0.032061</td>\n",
              "      <td>0.004515</td>\n",
              "      <td>0.004515</td>\n",
              "      <td>0.002185</td>\n",
              "      <td>0.027479</td>\n",
              "      <td>0.034553</td>\n",
              "      <td>0.006367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dbytes</th>\n",
              "      <td>0.144134</td>\n",
              "      <td>0.015812</td>\n",
              "      <td>0.035492</td>\n",
              "      <td>0.059759</td>\n",
              "      <td>0.206609</td>\n",
              "      <td>0.971907</td>\n",
              "      <td>0.009926</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.059475</td>\n",
              "      <td>0.135515</td>\n",
              "      <td>...</td>\n",
              "      <td>0.042633</td>\n",
              "      <td>0.052135</td>\n",
              "      <td>0.056901</td>\n",
              "      <td>0.054633</td>\n",
              "      <td>0.010460</td>\n",
              "      <td>0.010460</td>\n",
              "      <td>0.051403</td>\n",
              "      <td>0.045594</td>\n",
              "      <td>0.044531</td>\n",
              "      <td>0.013147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rate</th>\n",
              "      <td>0.120966</td>\n",
              "      <td>0.013924</td>\n",
              "      <td>0.141709</td>\n",
              "      <td>0.432307</td>\n",
              "      <td>0.076358</td>\n",
              "      <td>0.098202</td>\n",
              "      <td>0.028468</td>\n",
              "      <td>0.059475</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.407572</td>\n",
              "      <td>...</td>\n",
              "      <td>0.317229</td>\n",
              "      <td>0.353589</td>\n",
              "      <td>0.390721</td>\n",
              "      <td>0.383094</td>\n",
              "      <td>0.068140</td>\n",
              "      <td>0.068140</td>\n",
              "      <td>0.109297</td>\n",
              "      <td>0.310876</td>\n",
              "      <td>0.362883</td>\n",
              "      <td>0.072948</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sttl</th>\n",
              "      <td>0.012196</td>\n",
              "      <td>0.049944</td>\n",
              "      <td>0.295302</td>\n",
              "      <td>0.584697</td>\n",
              "      <td>0.102723</td>\n",
              "      <td>0.192580</td>\n",
              "      <td>0.020860</td>\n",
              "      <td>0.135515</td>\n",
              "      <td>0.407572</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.271383</td>\n",
              "      <td>0.344104</td>\n",
              "      <td>0.379930</td>\n",
              "      <td>0.404346</td>\n",
              "      <td>0.124157</td>\n",
              "      <td>0.124157</td>\n",
              "      <td>0.112833</td>\n",
              "      <td>0.273252</td>\n",
              "      <td>0.340678</td>\n",
              "      <td>0.220429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dttl</th>\n",
              "      <td>0.044159</td>\n",
              "      <td>0.113184</td>\n",
              "      <td>0.262970</td>\n",
              "      <td>0.375533</td>\n",
              "      <td>0.068246</td>\n",
              "      <td>0.053861</td>\n",
              "      <td>0.063009</td>\n",
              "      <td>0.023559</td>\n",
              "      <td>0.414546</td>\n",
              "      <td>0.032823</td>\n",
              "      <td>...</td>\n",
              "      <td>0.381678</td>\n",
              "      <td>0.366308</td>\n",
              "      <td>0.389429</td>\n",
              "      <td>0.403465</td>\n",
              "      <td>0.107208</td>\n",
              "      <td>0.107208</td>\n",
              "      <td>0.223652</td>\n",
              "      <td>0.365404</td>\n",
              "      <td>0.431188</td>\n",
              "      <td>0.091137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sload</th>\n",
              "      <td>0.081749</td>\n",
              "      <td>0.004759</td>\n",
              "      <td>0.166339</td>\n",
              "      <td>0.292570</td>\n",
              "      <td>0.051646</td>\n",
              "      <td>0.066710</td>\n",
              "      <td>0.018322</td>\n",
              "      <td>0.040430</td>\n",
              "      <td>0.602492</td>\n",
              "      <td>0.276475</td>\n",
              "      <td>...</td>\n",
              "      <td>0.076471</td>\n",
              "      <td>0.100118</td>\n",
              "      <td>0.082462</td>\n",
              "      <td>0.155030</td>\n",
              "      <td>0.046194</td>\n",
              "      <td>0.046194</td>\n",
              "      <td>0.073920</td>\n",
              "      <td>0.084412</td>\n",
              "      <td>0.141168</td>\n",
              "      <td>0.049327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dload</th>\n",
              "      <td>0.050603</td>\n",
              "      <td>0.046375</td>\n",
              "      <td>0.099581</td>\n",
              "      <td>0.150501</td>\n",
              "      <td>0.075897</td>\n",
              "      <td>0.139145</td>\n",
              "      <td>0.007829</td>\n",
              "      <td>0.104757</td>\n",
              "      <td>0.153051</td>\n",
              "      <td>0.397431</td>\n",
              "      <td>...</td>\n",
              "      <td>0.100953</td>\n",
              "      <td>0.143573</td>\n",
              "      <td>0.153429</td>\n",
              "      <td>0.161192</td>\n",
              "      <td>0.027810</td>\n",
              "      <td>0.027810</td>\n",
              "      <td>0.039246</td>\n",
              "      <td>0.098149</td>\n",
              "      <td>0.087247</td>\n",
              "      <td>0.035069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sloss</th>\n",
              "      <td>0.198597</td>\n",
              "      <td>0.011392</td>\n",
              "      <td>0.114522</td>\n",
              "      <td>0.060125</td>\n",
              "      <td>0.971069</td>\n",
              "      <td>0.204883</td>\n",
              "      <td>0.996109</td>\n",
              "      <td>0.017366</td>\n",
              "      <td>0.042923</td>\n",
              "      <td>0.044667</td>\n",
              "      <td>...</td>\n",
              "      <td>0.036965</td>\n",
              "      <td>0.039158</td>\n",
              "      <td>0.041109</td>\n",
              "      <td>0.045857</td>\n",
              "      <td>0.005688</td>\n",
              "      <td>0.005688</td>\n",
              "      <td>0.002049</td>\n",
              "      <td>0.038795</td>\n",
              "      <td>0.045459</td>\n",
              "      <td>0.009492</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dloss</th>\n",
              "      <td>0.142963</td>\n",
              "      <td>0.020002</td>\n",
              "      <td>0.051495</td>\n",
              "      <td>0.071056</td>\n",
              "      <td>0.207798</td>\n",
              "      <td>0.978636</td>\n",
              "      <td>0.006804</td>\n",
              "      <td>0.996504</td>\n",
              "      <td>0.075259</td>\n",
              "      <td>0.162628</td>\n",
              "      <td>...</td>\n",
              "      <td>0.054538</td>\n",
              "      <td>0.066411</td>\n",
              "      <td>0.072203</td>\n",
              "      <td>0.070905</td>\n",
              "      <td>0.007763</td>\n",
              "      <td>0.007763</td>\n",
              "      <td>0.048869</td>\n",
              "      <td>0.057412</td>\n",
              "      <td>0.058605</td>\n",
              "      <td>0.016669</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sinpkt</th>\n",
              "      <td>0.080055</td>\n",
              "      <td>0.562789</td>\n",
              "      <td>0.089971</td>\n",
              "      <td>0.095492</td>\n",
              "      <td>0.017587</td>\n",
              "      <td>0.022160</td>\n",
              "      <td>0.006565</td>\n",
              "      <td>0.013618</td>\n",
              "      <td>0.075745</td>\n",
              "      <td>0.206571</td>\n",
              "      <td>...</td>\n",
              "      <td>0.072241</td>\n",
              "      <td>0.060851</td>\n",
              "      <td>0.057659</td>\n",
              "      <td>0.081595</td>\n",
              "      <td>0.014458</td>\n",
              "      <td>0.014458</td>\n",
              "      <td>0.018829</td>\n",
              "      <td>0.081130</td>\n",
              "      <td>0.086988</td>\n",
              "      <td>0.941319</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dinpkt</th>\n",
              "      <td>0.152142</td>\n",
              "      <td>0.052417</td>\n",
              "      <td>0.020190</td>\n",
              "      <td>0.076235</td>\n",
              "      <td>0.001678</td>\n",
              "      <td>0.006514</td>\n",
              "      <td>0.000024</td>\n",
              "      <td>0.007701</td>\n",
              "      <td>0.051539</td>\n",
              "      <td>0.003215</td>\n",
              "      <td>...</td>\n",
              "      <td>0.042781</td>\n",
              "      <td>0.038731</td>\n",
              "      <td>0.039644</td>\n",
              "      <td>0.042856</td>\n",
              "      <td>0.002255</td>\n",
              "      <td>0.002255</td>\n",
              "      <td>0.046655</td>\n",
              "      <td>0.042445</td>\n",
              "      <td>0.045648</td>\n",
              "      <td>0.011306</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sjit</th>\n",
              "      <td>0.144413</td>\n",
              "      <td>0.016011</td>\n",
              "      <td>0.011469</td>\n",
              "      <td>0.045441</td>\n",
              "      <td>0.000384</td>\n",
              "      <td>0.000229</td>\n",
              "      <td>0.002054</td>\n",
              "      <td>0.002422</td>\n",
              "      <td>0.063370</td>\n",
              "      <td>0.022676</td>\n",
              "      <td>...</td>\n",
              "      <td>0.046592</td>\n",
              "      <td>0.043927</td>\n",
              "      <td>0.045747</td>\n",
              "      <td>0.047338</td>\n",
              "      <td>0.005798</td>\n",
              "      <td>0.005798</td>\n",
              "      <td>0.088052</td>\n",
              "      <td>0.045108</td>\n",
              "      <td>0.049711</td>\n",
              "      <td>0.013987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>djit</th>\n",
              "      <td>0.157443</td>\n",
              "      <td>0.019388</td>\n",
              "      <td>0.090262</td>\n",
              "      <td>0.064747</td>\n",
              "      <td>0.017096</td>\n",
              "      <td>0.054371</td>\n",
              "      <td>0.003516</td>\n",
              "      <td>0.047354</td>\n",
              "      <td>0.085802</td>\n",
              "      <td>0.123435</td>\n",
              "      <td>...</td>\n",
              "      <td>0.057296</td>\n",
              "      <td>0.071165</td>\n",
              "      <td>0.075841</td>\n",
              "      <td>0.081518</td>\n",
              "      <td>0.081014</td>\n",
              "      <td>0.081014</td>\n",
              "      <td>0.100563</td>\n",
              "      <td>0.062372</td>\n",
              "      <td>0.082087</td>\n",
              "      <td>0.018827</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>swin</th>\n",
              "      <td>0.022047</td>\n",
              "      <td>0.138967</td>\n",
              "      <td>0.292887</td>\n",
              "      <td>0.367493</td>\n",
              "      <td>0.131813</td>\n",
              "      <td>0.183703</td>\n",
              "      <td>0.050450</td>\n",
              "      <td>0.113148</td>\n",
              "      <td>0.515681</td>\n",
              "      <td>0.416843</td>\n",
              "      <td>...</td>\n",
              "      <td>0.412379</td>\n",
              "      <td>0.453084</td>\n",
              "      <td>0.497973</td>\n",
              "      <td>0.492118</td>\n",
              "      <td>0.129555</td>\n",
              "      <td>0.129555</td>\n",
              "      <td>0.207313</td>\n",
              "      <td>0.402189</td>\n",
              "      <td>0.466245</td>\n",
              "      <td>0.115622</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>stcpb</th>\n",
              "      <td>0.013183</td>\n",
              "      <td>0.108571</td>\n",
              "      <td>0.237103</td>\n",
              "      <td>0.314361</td>\n",
              "      <td>0.107410</td>\n",
              "      <td>0.144119</td>\n",
              "      <td>0.043164</td>\n",
              "      <td>0.086894</td>\n",
              "      <td>0.408750</td>\n",
              "      <td>0.337305</td>\n",
              "      <td>...</td>\n",
              "      <td>0.326216</td>\n",
              "      <td>0.353927</td>\n",
              "      <td>0.389607</td>\n",
              "      <td>0.394579</td>\n",
              "      <td>0.097536</td>\n",
              "      <td>0.097536</td>\n",
              "      <td>0.161696</td>\n",
              "      <td>0.318968</td>\n",
              "      <td>0.373117</td>\n",
              "      <td>0.090374</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dtcpb</th>\n",
              "      <td>0.014724</td>\n",
              "      <td>0.108630</td>\n",
              "      <td>0.237723</td>\n",
              "      <td>0.313922</td>\n",
              "      <td>0.102161</td>\n",
              "      <td>0.142667</td>\n",
              "      <td>0.037988</td>\n",
              "      <td>0.086453</td>\n",
              "      <td>0.409046</td>\n",
              "      <td>0.334114</td>\n",
              "      <td>...</td>\n",
              "      <td>0.327530</td>\n",
              "      <td>0.354069</td>\n",
              "      <td>0.389581</td>\n",
              "      <td>0.394566</td>\n",
              "      <td>0.100410</td>\n",
              "      <td>0.100410</td>\n",
              "      <td>0.172032</td>\n",
              "      <td>0.317651</td>\n",
              "      <td>0.374050</td>\n",
              "      <td>0.090525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dwin</th>\n",
              "      <td>0.017527</td>\n",
              "      <td>0.137605</td>\n",
              "      <td>0.300035</td>\n",
              "      <td>0.397710</td>\n",
              "      <td>0.133102</td>\n",
              "      <td>0.185555</td>\n",
              "      <td>0.050981</td>\n",
              "      <td>0.114269</td>\n",
              "      <td>0.518117</td>\n",
              "      <td>0.424320</td>\n",
              "      <td>...</td>\n",
              "      <td>0.415255</td>\n",
              "      <td>0.448574</td>\n",
              "      <td>0.493572</td>\n",
              "      <td>0.499716</td>\n",
              "      <td>0.130834</td>\n",
              "      <td>0.130834</td>\n",
              "      <td>0.209360</td>\n",
              "      <td>0.403987</td>\n",
              "      <td>0.473821</td>\n",
              "      <td>0.114671</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tcprtt</th>\n",
              "      <td>0.053125</td>\n",
              "      <td>0.079193</td>\n",
              "      <td>0.140239</td>\n",
              "      <td>0.278469</td>\n",
              "      <td>0.039187</td>\n",
              "      <td>0.020915</td>\n",
              "      <td>0.043624</td>\n",
              "      <td>0.003907</td>\n",
              "      <td>0.300794</td>\n",
              "      <td>0.039777</td>\n",
              "      <td>...</td>\n",
              "      <td>0.286773</td>\n",
              "      <td>0.264803</td>\n",
              "      <td>0.280883</td>\n",
              "      <td>0.290241</td>\n",
              "      <td>0.067715</td>\n",
              "      <td>0.067715</td>\n",
              "      <td>0.163332</td>\n",
              "      <td>0.278013</td>\n",
              "      <td>0.316713</td>\n",
              "      <td>0.065994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>synack</th>\n",
              "      <td>0.051093</td>\n",
              "      <td>0.073528</td>\n",
              "      <td>0.110995</td>\n",
              "      <td>0.261882</td>\n",
              "      <td>0.035507</td>\n",
              "      <td>0.015936</td>\n",
              "      <td>0.039739</td>\n",
              "      <td>0.000101</td>\n",
              "      <td>0.279271</td>\n",
              "      <td>0.042590</td>\n",
              "      <td>...</td>\n",
              "      <td>0.264577</td>\n",
              "      <td>0.244511</td>\n",
              "      <td>0.260560</td>\n",
              "      <td>0.265808</td>\n",
              "      <td>0.056794</td>\n",
              "      <td>0.056794</td>\n",
              "      <td>0.144906</td>\n",
              "      <td>0.256475</td>\n",
              "      <td>0.289605</td>\n",
              "      <td>0.061274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ackdat</th>\n",
              "      <td>0.049332</td>\n",
              "      <td>0.076362</td>\n",
              "      <td>0.155811</td>\n",
              "      <td>0.264946</td>\n",
              "      <td>0.038725</td>\n",
              "      <td>0.023899</td>\n",
              "      <td>0.042883</td>\n",
              "      <td>0.007546</td>\n",
              "      <td>0.290051</td>\n",
              "      <td>0.032293</td>\n",
              "      <td>...</td>\n",
              "      <td>0.278326</td>\n",
              "      <td>0.256785</td>\n",
              "      <td>0.271092</td>\n",
              "      <td>0.283801</td>\n",
              "      <td>0.071807</td>\n",
              "      <td>0.071807</td>\n",
              "      <td>0.164719</td>\n",
              "      <td>0.269845</td>\n",
              "      <td>0.310164</td>\n",
              "      <td>0.063635</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>smean</th>\n",
              "      <td>0.090028</td>\n",
              "      <td>0.042157</td>\n",
              "      <td>0.224861</td>\n",
              "      <td>0.070796</td>\n",
              "      <td>0.216592</td>\n",
              "      <td>0.014697</td>\n",
              "      <td>0.232348</td>\n",
              "      <td>0.036635</td>\n",
              "      <td>0.113232</td>\n",
              "      <td>0.010029</td>\n",
              "      <td>...</td>\n",
              "      <td>0.162651</td>\n",
              "      <td>0.169091</td>\n",
              "      <td>0.199021</td>\n",
              "      <td>0.152219</td>\n",
              "      <td>0.043298</td>\n",
              "      <td>0.043298</td>\n",
              "      <td>0.017901</td>\n",
              "      <td>0.159718</td>\n",
              "      <td>0.171203</td>\n",
              "      <td>0.056094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dmean</th>\n",
              "      <td>0.025336</td>\n",
              "      <td>0.077296</td>\n",
              "      <td>0.145641</td>\n",
              "      <td>0.256392</td>\n",
              "      <td>0.150237</td>\n",
              "      <td>0.441445</td>\n",
              "      <td>0.004973</td>\n",
              "      <td>0.419965</td>\n",
              "      <td>0.273323</td>\n",
              "      <td>0.550389</td>\n",
              "      <td>...</td>\n",
              "      <td>0.203729</td>\n",
              "      <td>0.244463</td>\n",
              "      <td>0.264171</td>\n",
              "      <td>0.279326</td>\n",
              "      <td>0.023999</td>\n",
              "      <td>0.023999</td>\n",
              "      <td>0.129436</td>\n",
              "      <td>0.201604</td>\n",
              "      <td>0.227964</td>\n",
              "      <td>0.060813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>trans_depth</th>\n",
              "      <td>0.002071</td>\n",
              "      <td>0.020709</td>\n",
              "      <td>0.191839</td>\n",
              "      <td>0.056128</td>\n",
              "      <td>0.008834</td>\n",
              "      <td>0.029042</td>\n",
              "      <td>0.003428</td>\n",
              "      <td>0.030912</td>\n",
              "      <td>0.078556</td>\n",
              "      <td>0.063904</td>\n",
              "      <td>...</td>\n",
              "      <td>0.069216</td>\n",
              "      <td>0.069969</td>\n",
              "      <td>0.073894</td>\n",
              "      <td>0.084412</td>\n",
              "      <td>0.016177</td>\n",
              "      <td>0.016177</td>\n",
              "      <td>0.226152</td>\n",
              "      <td>0.065314</td>\n",
              "      <td>0.093901</td>\n",
              "      <td>0.017258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>response_body_len</th>\n",
              "      <td>0.078915</td>\n",
              "      <td>0.006005</td>\n",
              "      <td>0.056951</td>\n",
              "      <td>0.025541</td>\n",
              "      <td>0.087217</td>\n",
              "      <td>0.442194</td>\n",
              "      <td>0.001620</td>\n",
              "      <td>0.470905</td>\n",
              "      <td>0.022752</td>\n",
              "      <td>0.050454</td>\n",
              "      <td>...</td>\n",
              "      <td>0.016102</td>\n",
              "      <td>0.020611</td>\n",
              "      <td>0.021715</td>\n",
              "      <td>0.021633</td>\n",
              "      <td>0.004691</td>\n",
              "      <td>0.004691</td>\n",
              "      <td>0.065238</td>\n",
              "      <td>0.018091</td>\n",
              "      <td>0.027303</td>\n",
              "      <td>0.005004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ct_srv_src</th>\n",
              "      <td>0.113709</td>\n",
              "      <td>0.203057</td>\n",
              "      <td>0.058269</td>\n",
              "      <td>0.385515</td>\n",
              "      <td>0.069127</td>\n",
              "      <td>0.079095</td>\n",
              "      <td>0.034395</td>\n",
              "      <td>0.045529</td>\n",
              "      <td>0.357704</td>\n",
              "      <td>0.346079</td>\n",
              "      <td>...</td>\n",
              "      <td>0.841280</td>\n",
              "      <td>0.866010</td>\n",
              "      <td>0.823583</td>\n",
              "      <td>0.967138</td>\n",
              "      <td>0.089827</td>\n",
              "      <td>0.089827</td>\n",
              "      <td>0.120111</td>\n",
              "      <td>0.781051</td>\n",
              "      <td>0.980323</td>\n",
              "      <td>0.088456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ct_state_ttl</th>\n",
              "      <td>0.186293</td>\n",
              "      <td>0.162433</td>\n",
              "      <td>0.205943</td>\n",
              "      <td>0.759825</td>\n",
              "      <td>0.086170</td>\n",
              "      <td>0.150023</td>\n",
              "      <td>0.012053</td>\n",
              "      <td>0.089944</td>\n",
              "      <td>0.431534</td>\n",
              "      <td>0.672325</td>\n",
              "      <td>...</td>\n",
              "      <td>0.302420</td>\n",
              "      <td>0.353778</td>\n",
              "      <td>0.393091</td>\n",
              "      <td>0.427705</td>\n",
              "      <td>0.075058</td>\n",
              "      <td>0.075058</td>\n",
              "      <td>0.097270</td>\n",
              "      <td>0.296638</td>\n",
              "      <td>0.364200</td>\n",
              "      <td>0.092616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ct_dst_ltm</th>\n",
              "      <td>0.086300</td>\n",
              "      <td>0.191101</td>\n",
              "      <td>0.047685</td>\n",
              "      <td>0.328748</td>\n",
              "      <td>0.060194</td>\n",
              "      <td>0.071909</td>\n",
              "      <td>0.026661</td>\n",
              "      <td>0.042633</td>\n",
              "      <td>0.317229</td>\n",
              "      <td>0.271383</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.962052</td>\n",
              "      <td>0.870644</td>\n",
              "      <td>0.852252</td>\n",
              "      <td>0.048527</td>\n",
              "      <td>0.048527</td>\n",
              "      <td>0.085540</td>\n",
              "      <td>0.886072</td>\n",
              "      <td>0.852583</td>\n",
              "      <td>0.069455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ct_src_dport_ltm</th>\n",
              "      <td>0.094091</td>\n",
              "      <td>0.174965</td>\n",
              "      <td>0.038347</td>\n",
              "      <td>0.372309</td>\n",
              "      <td>0.068373</td>\n",
              "      <td>0.086695</td>\n",
              "      <td>0.026490</td>\n",
              "      <td>0.052135</td>\n",
              "      <td>0.353589</td>\n",
              "      <td>0.344104</td>\n",
              "      <td>...</td>\n",
              "      <td>0.962052</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.906793</td>\n",
              "      <td>0.869941</td>\n",
              "      <td>0.064055</td>\n",
              "      <td>0.064055</td>\n",
              "      <td>0.085699</td>\n",
              "      <td>0.897438</td>\n",
              "      <td>0.868850</td>\n",
              "      <td>0.056858</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ct_dst_sport_ltm</th>\n",
              "      <td>0.093923</td>\n",
              "      <td>0.165796</td>\n",
              "      <td>0.051106</td>\n",
              "      <td>0.408662</td>\n",
              "      <td>0.072484</td>\n",
              "      <td>0.094267</td>\n",
              "      <td>0.027281</td>\n",
              "      <td>0.056901</td>\n",
              "      <td>0.390721</td>\n",
              "      <td>0.379930</td>\n",
              "      <td>...</td>\n",
              "      <td>0.870644</td>\n",
              "      <td>0.906793</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.838678</td>\n",
              "      <td>0.065305</td>\n",
              "      <td>0.065305</td>\n",
              "      <td>0.086594</td>\n",
              "      <td>0.803013</td>\n",
              "      <td>0.830152</td>\n",
              "      <td>0.053224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ct_dst_src_ltm</th>\n",
              "      <td>0.101760</td>\n",
              "      <td>0.175708</td>\n",
              "      <td>0.006774</td>\n",
              "      <td>0.429906</td>\n",
              "      <td>0.077553</td>\n",
              "      <td>0.094085</td>\n",
              "      <td>0.032061</td>\n",
              "      <td>0.054633</td>\n",
              "      <td>0.383094</td>\n",
              "      <td>0.404346</td>\n",
              "      <td>...</td>\n",
              "      <td>0.852252</td>\n",
              "      <td>0.869941</td>\n",
              "      <td>0.838678</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.062574</td>\n",
              "      <td>0.062574</td>\n",
              "      <td>0.106129</td>\n",
              "      <td>0.783753</td>\n",
              "      <td>0.972370</td>\n",
              "      <td>0.079765</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>is_ftp_login</th>\n",
              "      <td>0.020641</td>\n",
              "      <td>0.018003</td>\n",
              "      <td>0.071051</td>\n",
              "      <td>0.051970</td>\n",
              "      <td>0.009951</td>\n",
              "      <td>0.013491</td>\n",
              "      <td>0.004515</td>\n",
              "      <td>0.010460</td>\n",
              "      <td>0.068140</td>\n",
              "      <td>0.124157</td>\n",
              "      <td>...</td>\n",
              "      <td>0.048527</td>\n",
              "      <td>0.064055</td>\n",
              "      <td>0.065305</td>\n",
              "      <td>0.062574</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.022505</td>\n",
              "      <td>0.046326</td>\n",
              "      <td>0.087511</td>\n",
              "      <td>0.015003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ct_ftp_cmd</th>\n",
              "      <td>0.020641</td>\n",
              "      <td>0.018003</td>\n",
              "      <td>0.071051</td>\n",
              "      <td>0.051970</td>\n",
              "      <td>0.009951</td>\n",
              "      <td>0.013491</td>\n",
              "      <td>0.004515</td>\n",
              "      <td>0.010460</td>\n",
              "      <td>0.068140</td>\n",
              "      <td>0.124157</td>\n",
              "      <td>...</td>\n",
              "      <td>0.048527</td>\n",
              "      <td>0.064055</td>\n",
              "      <td>0.065305</td>\n",
              "      <td>0.062574</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.022505</td>\n",
              "      <td>0.046326</td>\n",
              "      <td>0.087511</td>\n",
              "      <td>0.015003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ct_flw_http_mthd</th>\n",
              "      <td>0.024743</td>\n",
              "      <td>0.028809</td>\n",
              "      <td>0.266206</td>\n",
              "      <td>0.078856</td>\n",
              "      <td>0.006084</td>\n",
              "      <td>0.047974</td>\n",
              "      <td>0.002185</td>\n",
              "      <td>0.051403</td>\n",
              "      <td>0.109297</td>\n",
              "      <td>0.112833</td>\n",
              "      <td>...</td>\n",
              "      <td>0.085540</td>\n",
              "      <td>0.085699</td>\n",
              "      <td>0.086594</td>\n",
              "      <td>0.106129</td>\n",
              "      <td>0.022505</td>\n",
              "      <td>0.022505</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.074768</td>\n",
              "      <td>0.118709</td>\n",
              "      <td>0.024007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ct_src_ltm</th>\n",
              "      <td>0.080871</td>\n",
              "      <td>0.168121</td>\n",
              "      <td>0.028599</td>\n",
              "      <td>0.323019</td>\n",
              "      <td>0.061584</td>\n",
              "      <td>0.075190</td>\n",
              "      <td>0.027479</td>\n",
              "      <td>0.045594</td>\n",
              "      <td>0.310876</td>\n",
              "      <td>0.273252</td>\n",
              "      <td>...</td>\n",
              "      <td>0.886072</td>\n",
              "      <td>0.897438</td>\n",
              "      <td>0.803013</td>\n",
              "      <td>0.783753</td>\n",
              "      <td>0.046326</td>\n",
              "      <td>0.046326</td>\n",
              "      <td>0.074768</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.777891</td>\n",
              "      <td>0.078886</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ct_srv_dst</th>\n",
              "      <td>0.115336</td>\n",
              "      <td>0.198594</td>\n",
              "      <td>0.048011</td>\n",
              "      <td>0.387446</td>\n",
              "      <td>0.069598</td>\n",
              "      <td>0.078342</td>\n",
              "      <td>0.034553</td>\n",
              "      <td>0.044531</td>\n",
              "      <td>0.362883</td>\n",
              "      <td>0.340678</td>\n",
              "      <td>...</td>\n",
              "      <td>0.852583</td>\n",
              "      <td>0.868850</td>\n",
              "      <td>0.830152</td>\n",
              "      <td>0.972370</td>\n",
              "      <td>0.087511</td>\n",
              "      <td>0.087511</td>\n",
              "      <td>0.118709</td>\n",
              "      <td>0.777891</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.085149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>is_sm_ips_ports</th>\n",
              "      <td>0.035370</td>\n",
              "      <td>0.585941</td>\n",
              "      <td>0.088847</td>\n",
              "      <td>0.094198</td>\n",
              "      <td>0.017770</td>\n",
              "      <td>0.021765</td>\n",
              "      <td>0.006367</td>\n",
              "      <td>0.013147</td>\n",
              "      <td>0.072948</td>\n",
              "      <td>0.220429</td>\n",
              "      <td>...</td>\n",
              "      <td>0.069455</td>\n",
              "      <td>0.056858</td>\n",
              "      <td>0.053224</td>\n",
              "      <td>0.079765</td>\n",
              "      <td>0.015003</td>\n",
              "      <td>0.015003</td>\n",
              "      <td>0.024007</td>\n",
              "      <td>0.078886</td>\n",
              "      <td>0.085149</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>42 rows Ã— 42 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                        dur     proto   service     state     spkts     dpkts  \\\n",
              "dur                1.000000  0.124502  0.008234  0.103443  0.254559  0.181182   \n",
              "proto              0.124502  1.000000  0.170032  0.172441  0.013469  0.026439   \n",
              "service            0.008234  0.170032  1.000000  0.144978  0.114403  0.077338   \n",
              "state              0.103443  0.172441  0.144978  1.000000  0.078701  0.098268   \n",
              "spkts              0.254559  0.013469  0.114403  0.078701  1.000000  0.390067   \n",
              "dpkts              0.181182  0.026439  0.077338  0.098268  0.390067  1.000000   \n",
              "sbytes             0.199731  0.005920  0.105188  0.049300  0.963791  0.188476   \n",
              "dbytes             0.144134  0.015812  0.035492  0.059759  0.206609  0.971907   \n",
              "rate               0.120966  0.013924  0.141709  0.432307  0.076358  0.098202   \n",
              "sttl               0.012196  0.049944  0.295302  0.584697  0.102723  0.192580   \n",
              "dttl               0.044159  0.113184  0.262970  0.375533  0.068246  0.053861   \n",
              "sload              0.081749  0.004759  0.166339  0.292570  0.051646  0.066710   \n",
              "dload              0.050603  0.046375  0.099581  0.150501  0.075897  0.139145   \n",
              "sloss              0.198597  0.011392  0.114522  0.060125  0.971069  0.204883   \n",
              "dloss              0.142963  0.020002  0.051495  0.071056  0.207798  0.978636   \n",
              "sinpkt             0.080055  0.562789  0.089971  0.095492  0.017587  0.022160   \n",
              "dinpkt             0.152142  0.052417  0.020190  0.076235  0.001678  0.006514   \n",
              "sjit               0.144413  0.016011  0.011469  0.045441  0.000384  0.000229   \n",
              "djit               0.157443  0.019388  0.090262  0.064747  0.017096  0.054371   \n",
              "swin               0.022047  0.138967  0.292887  0.367493  0.131813  0.183703   \n",
              "stcpb              0.013183  0.108571  0.237103  0.314361  0.107410  0.144119   \n",
              "dtcpb              0.014724  0.108630  0.237723  0.313922  0.102161  0.142667   \n",
              "dwin               0.017527  0.137605  0.300035  0.397710  0.133102  0.185555   \n",
              "tcprtt             0.053125  0.079193  0.140239  0.278469  0.039187  0.020915   \n",
              "synack             0.051093  0.073528  0.110995  0.261882  0.035507  0.015936   \n",
              "ackdat             0.049332  0.076362  0.155811  0.264946  0.038725  0.023899   \n",
              "smean              0.090028  0.042157  0.224861  0.070796  0.216592  0.014697   \n",
              "dmean              0.025336  0.077296  0.145641  0.256392  0.150237  0.441445   \n",
              "trans_depth        0.002071  0.020709  0.191839  0.056128  0.008834  0.029042   \n",
              "response_body_len  0.078915  0.006005  0.056951  0.025541  0.087217  0.442194   \n",
              "ct_srv_src         0.113709  0.203057  0.058269  0.385515  0.069127  0.079095   \n",
              "ct_state_ttl       0.186293  0.162433  0.205943  0.759825  0.086170  0.150023   \n",
              "ct_dst_ltm         0.086300  0.191101  0.047685  0.328748  0.060194  0.071909   \n",
              "ct_src_dport_ltm   0.094091  0.174965  0.038347  0.372309  0.068373  0.086695   \n",
              "ct_dst_sport_ltm   0.093923  0.165796  0.051106  0.408662  0.072484  0.094267   \n",
              "ct_dst_src_ltm     0.101760  0.175708  0.006774  0.429906  0.077553  0.094085   \n",
              "is_ftp_login       0.020641  0.018003  0.071051  0.051970  0.009951  0.013491   \n",
              "ct_ftp_cmd         0.020641  0.018003  0.071051  0.051970  0.009951  0.013491   \n",
              "ct_flw_http_mthd   0.024743  0.028809  0.266206  0.078856  0.006084  0.047974   \n",
              "ct_src_ltm         0.080871  0.168121  0.028599  0.323019  0.061584  0.075190   \n",
              "ct_srv_dst         0.115336  0.198594  0.048011  0.387446  0.069598  0.078342   \n",
              "is_sm_ips_ports    0.035370  0.585941  0.088847  0.094198  0.017770  0.021765   \n",
              "\n",
              "                     sbytes    dbytes      rate      sttl  ...  ct_dst_ltm  \\\n",
              "dur                0.199731  0.144134  0.120966  0.012196  ...    0.086300   \n",
              "proto              0.005920  0.015812  0.013924  0.049944  ...    0.191101   \n",
              "service            0.105188  0.035492  0.141709  0.295302  ...    0.047685   \n",
              "state              0.049300  0.059759  0.432307  0.584697  ...    0.328748   \n",
              "spkts              0.963791  0.206609  0.076358  0.102723  ...    0.060194   \n",
              "dpkts              0.188476  0.971907  0.098202  0.192580  ...    0.071909   \n",
              "sbytes             1.000000  0.009926  0.028468  0.020860  ...    0.026661   \n",
              "dbytes             0.009926  1.000000  0.059475  0.135515  ...    0.042633   \n",
              "rate               0.028468  0.059475  1.000000  0.407572  ...    0.317229   \n",
              "sttl               0.020860  0.135515  0.407572  1.000000  ...    0.271383   \n",
              "dttl               0.063009  0.023559  0.414546  0.032823  ...    0.381678   \n",
              "sload              0.018322  0.040430  0.602492  0.276475  ...    0.076471   \n",
              "dload              0.007829  0.104757  0.153051  0.397431  ...    0.100953   \n",
              "sloss              0.996109  0.017366  0.042923  0.044667  ...    0.036965   \n",
              "dloss              0.006804  0.996504  0.075259  0.162628  ...    0.054538   \n",
              "sinpkt             0.006565  0.013618  0.075745  0.206571  ...    0.072241   \n",
              "dinpkt             0.000024  0.007701  0.051539  0.003215  ...    0.042781   \n",
              "sjit               0.002054  0.002422  0.063370  0.022676  ...    0.046592   \n",
              "djit               0.003516  0.047354  0.085802  0.123435  ...    0.057296   \n",
              "swin               0.050450  0.113148  0.515681  0.416843  ...    0.412379   \n",
              "stcpb              0.043164  0.086894  0.408750  0.337305  ...    0.326216   \n",
              "dtcpb              0.037988  0.086453  0.409046  0.334114  ...    0.327530   \n",
              "dwin               0.050981  0.114269  0.518117  0.424320  ...    0.415255   \n",
              "tcprtt             0.043624  0.003907  0.300794  0.039777  ...    0.286773   \n",
              "synack             0.039739  0.000101  0.279271  0.042590  ...    0.264577   \n",
              "ackdat             0.042883  0.007546  0.290051  0.032293  ...    0.278326   \n",
              "smean              0.232348  0.036635  0.113232  0.010029  ...    0.162651   \n",
              "dmean              0.004973  0.419965  0.273323  0.550389  ...    0.203729   \n",
              "trans_depth        0.003428  0.030912  0.078556  0.063904  ...    0.069216   \n",
              "response_body_len  0.001620  0.470905  0.022752  0.050454  ...    0.016102   \n",
              "ct_srv_src         0.034395  0.045529  0.357704  0.346079  ...    0.841280   \n",
              "ct_state_ttl       0.012053  0.089944  0.431534  0.672325  ...    0.302420   \n",
              "ct_dst_ltm         0.026661  0.042633  0.317229  0.271383  ...    1.000000   \n",
              "ct_src_dport_ltm   0.026490  0.052135  0.353589  0.344104  ...    0.962052   \n",
              "ct_dst_sport_ltm   0.027281  0.056901  0.390721  0.379930  ...    0.870644   \n",
              "ct_dst_src_ltm     0.032061  0.054633  0.383094  0.404346  ...    0.852252   \n",
              "is_ftp_login       0.004515  0.010460  0.068140  0.124157  ...    0.048527   \n",
              "ct_ftp_cmd         0.004515  0.010460  0.068140  0.124157  ...    0.048527   \n",
              "ct_flw_http_mthd   0.002185  0.051403  0.109297  0.112833  ...    0.085540   \n",
              "ct_src_ltm         0.027479  0.045594  0.310876  0.273252  ...    0.886072   \n",
              "ct_srv_dst         0.034553  0.044531  0.362883  0.340678  ...    0.852583   \n",
              "is_sm_ips_ports    0.006367  0.013147  0.072948  0.220429  ...    0.069455   \n",
              "\n",
              "                   ct_src_dport_ltm  ct_dst_sport_ltm  ct_dst_src_ltm  \\\n",
              "dur                        0.094091          0.093923        0.101760   \n",
              "proto                      0.174965          0.165796        0.175708   \n",
              "service                    0.038347          0.051106        0.006774   \n",
              "state                      0.372309          0.408662        0.429906   \n",
              "spkts                      0.068373          0.072484        0.077553   \n",
              "dpkts                      0.086695          0.094267        0.094085   \n",
              "sbytes                     0.026490          0.027281        0.032061   \n",
              "dbytes                     0.052135          0.056901        0.054633   \n",
              "rate                       0.353589          0.390721        0.383094   \n",
              "sttl                       0.344104          0.379930        0.404346   \n",
              "dttl                       0.366308          0.389429        0.403465   \n",
              "sload                      0.100118          0.082462        0.155030   \n",
              "dload                      0.143573          0.153429        0.161192   \n",
              "sloss                      0.039158          0.041109        0.045857   \n",
              "dloss                      0.066411          0.072203        0.070905   \n",
              "sinpkt                     0.060851          0.057659        0.081595   \n",
              "dinpkt                     0.038731          0.039644        0.042856   \n",
              "sjit                       0.043927          0.045747        0.047338   \n",
              "djit                       0.071165          0.075841        0.081518   \n",
              "swin                       0.453084          0.497973        0.492118   \n",
              "stcpb                      0.353927          0.389607        0.394579   \n",
              "dtcpb                      0.354069          0.389581        0.394566   \n",
              "dwin                       0.448574          0.493572        0.499716   \n",
              "tcprtt                     0.264803          0.280883        0.290241   \n",
              "synack                     0.244511          0.260560        0.265808   \n",
              "ackdat                     0.256785          0.271092        0.283801   \n",
              "smean                      0.169091          0.199021        0.152219   \n",
              "dmean                      0.244463          0.264171        0.279326   \n",
              "trans_depth                0.069969          0.073894        0.084412   \n",
              "response_body_len          0.020611          0.021715        0.021633   \n",
              "ct_srv_src                 0.866010          0.823583        0.967138   \n",
              "ct_state_ttl               0.353778          0.393091        0.427705   \n",
              "ct_dst_ltm                 0.962052          0.870644        0.852252   \n",
              "ct_src_dport_ltm           1.000000          0.906793        0.869941   \n",
              "ct_dst_sport_ltm           0.906793          1.000000        0.838678   \n",
              "ct_dst_src_ltm             0.869941          0.838678        1.000000   \n",
              "is_ftp_login               0.064055          0.065305        0.062574   \n",
              "ct_ftp_cmd                 0.064055          0.065305        0.062574   \n",
              "ct_flw_http_mthd           0.085699          0.086594        0.106129   \n",
              "ct_src_ltm                 0.897438          0.803013        0.783753   \n",
              "ct_srv_dst                 0.868850          0.830152        0.972370   \n",
              "is_sm_ips_ports            0.056858          0.053224        0.079765   \n",
              "\n",
              "                   is_ftp_login  ct_ftp_cmd  ct_flw_http_mthd  ct_src_ltm  \\\n",
              "dur                    0.020641    0.020641          0.024743    0.080871   \n",
              "proto                  0.018003    0.018003          0.028809    0.168121   \n",
              "service                0.071051    0.071051          0.266206    0.028599   \n",
              "state                  0.051970    0.051970          0.078856    0.323019   \n",
              "spkts                  0.009951    0.009951          0.006084    0.061584   \n",
              "dpkts                  0.013491    0.013491          0.047974    0.075190   \n",
              "sbytes                 0.004515    0.004515          0.002185    0.027479   \n",
              "dbytes                 0.010460    0.010460          0.051403    0.045594   \n",
              "rate                   0.068140    0.068140          0.109297    0.310876   \n",
              "sttl                   0.124157    0.124157          0.112833    0.273252   \n",
              "dttl                   0.107208    0.107208          0.223652    0.365404   \n",
              "sload                  0.046194    0.046194          0.073920    0.084412   \n",
              "dload                  0.027810    0.027810          0.039246    0.098149   \n",
              "sloss                  0.005688    0.005688          0.002049    0.038795   \n",
              "dloss                  0.007763    0.007763          0.048869    0.057412   \n",
              "sinpkt                 0.014458    0.014458          0.018829    0.081130   \n",
              "dinpkt                 0.002255    0.002255          0.046655    0.042445   \n",
              "sjit                   0.005798    0.005798          0.088052    0.045108   \n",
              "djit                   0.081014    0.081014          0.100563    0.062372   \n",
              "swin                   0.129555    0.129555          0.207313    0.402189   \n",
              "stcpb                  0.097536    0.097536          0.161696    0.318968   \n",
              "dtcpb                  0.100410    0.100410          0.172032    0.317651   \n",
              "dwin                   0.130834    0.130834          0.209360    0.403987   \n",
              "tcprtt                 0.067715    0.067715          0.163332    0.278013   \n",
              "synack                 0.056794    0.056794          0.144906    0.256475   \n",
              "ackdat                 0.071807    0.071807          0.164719    0.269845   \n",
              "smean                  0.043298    0.043298          0.017901    0.159718   \n",
              "dmean                  0.023999    0.023999          0.129436    0.201604   \n",
              "trans_depth            0.016177    0.016177          0.226152    0.065314   \n",
              "response_body_len      0.004691    0.004691          0.065238    0.018091   \n",
              "ct_srv_src             0.089827    0.089827          0.120111    0.781051   \n",
              "ct_state_ttl           0.075058    0.075058          0.097270    0.296638   \n",
              "ct_dst_ltm             0.048527    0.048527          0.085540    0.886072   \n",
              "ct_src_dport_ltm       0.064055    0.064055          0.085699    0.897438   \n",
              "ct_dst_sport_ltm       0.065305    0.065305          0.086594    0.803013   \n",
              "ct_dst_src_ltm         0.062574    0.062574          0.106129    0.783753   \n",
              "is_ftp_login           1.000000    1.000000          0.022505    0.046326   \n",
              "ct_ftp_cmd             1.000000    1.000000          0.022505    0.046326   \n",
              "ct_flw_http_mthd       0.022505    0.022505          1.000000    0.074768   \n",
              "ct_src_ltm             0.046326    0.046326          0.074768    1.000000   \n",
              "ct_srv_dst             0.087511    0.087511          0.118709    0.777891   \n",
              "is_sm_ips_ports        0.015003    0.015003          0.024007    0.078886   \n",
              "\n",
              "                   ct_srv_dst  is_sm_ips_ports  \n",
              "dur                  0.115336         0.035370  \n",
              "proto                0.198594         0.585941  \n",
              "service              0.048011         0.088847  \n",
              "state                0.387446         0.094198  \n",
              "spkts                0.069598         0.017770  \n",
              "dpkts                0.078342         0.021765  \n",
              "sbytes               0.034553         0.006367  \n",
              "dbytes               0.044531         0.013147  \n",
              "rate                 0.362883         0.072948  \n",
              "sttl                 0.340678         0.220429  \n",
              "dttl                 0.431188         0.091137  \n",
              "sload                0.141168         0.049327  \n",
              "dload                0.087247         0.035069  \n",
              "sloss                0.045459         0.009492  \n",
              "dloss                0.058605         0.016669  \n",
              "sinpkt               0.086988         0.941319  \n",
              "dinpkt               0.045648         0.011306  \n",
              "sjit                 0.049711         0.013987  \n",
              "djit                 0.082087         0.018827  \n",
              "swin                 0.466245         0.115622  \n",
              "stcpb                0.373117         0.090374  \n",
              "dtcpb                0.374050         0.090525  \n",
              "dwin                 0.473821         0.114671  \n",
              "tcprtt               0.316713         0.065994  \n",
              "synack               0.289605         0.061274  \n",
              "ackdat               0.310164         0.063635  \n",
              "smean                0.171203         0.056094  \n",
              "dmean                0.227964         0.060813  \n",
              "trans_depth          0.093901         0.017258  \n",
              "response_body_len    0.027303         0.005004  \n",
              "ct_srv_src           0.980323         0.088456  \n",
              "ct_state_ttl         0.364200         0.092616  \n",
              "ct_dst_ltm           0.852583         0.069455  \n",
              "ct_src_dport_ltm     0.868850         0.056858  \n",
              "ct_dst_sport_ltm     0.830152         0.053224  \n",
              "ct_dst_src_ltm       0.972370         0.079765  \n",
              "is_ftp_login         0.087511         0.015003  \n",
              "ct_ftp_cmd           0.087511         0.015003  \n",
              "ct_flw_http_mthd     0.118709         0.024007  \n",
              "ct_src_ltm           0.777891         0.078886  \n",
              "ct_srv_dst           1.000000         0.085149  \n",
              "is_sm_ips_ports      0.085149         1.000000  \n",
              "\n",
              "[42 rows x 42 columns]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corr_matrix = df_feature_analysis.corr().apply(abs)\n",
        "corr_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJOTcJuNjxbp",
        "outputId": "55ff36fb-9633-427f-b5d0-698e8c9cf256"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'is_ftp_login': {'feature': 'ct_ftp_cmd', 'score': np.float64(1.0)},\n",
              " 'dbytes': {'feature': 'dloss', 'score': np.float64(0.996503594762374)},\n",
              " 'sbytes': {'feature': 'sloss', 'score': np.float64(0.9961094729147967)},\n",
              " 'swin': {'feature': 'dwin', 'score': np.float64(0.9901399299415929)},\n",
              " 'ct_srv_src': {'feature': 'ct_srv_dst',\n",
              "  'score': np.float64(0.9803230099911133)},\n",
              " 'dpkts': {'feature': 'dloss', 'score': np.float64(0.9786363765710283)},\n",
              " 'ct_dst_src_ltm': {'feature': 'ct_srv_dst',\n",
              "  'score': np.float64(0.9723704538697349)},\n",
              " 'spkts': {'feature': 'sloss', 'score': np.float64(0.9710686917738162)},\n",
              " 'ct_dst_ltm': {'feature': 'ct_src_dport_ltm',\n",
              "  'score': np.float64(0.9620518416459877)},\n",
              " 'tcprtt': {'feature': 'synack', 'score': np.float64(0.9494676611067793)},\n",
              " 'ackdat': {'feature': 'tcprtt', 'score': np.float64(0.941760373812716)},\n",
              " 'sinpkt': {'feature': 'is_sm_ips_ports',\n",
              "  'score': np.float64(0.941318900735516)}}"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corr_feature={}\n",
        "corr_tresh= 0.94\n",
        "\n",
        "for feature in df_feature_analysis.columns:\n",
        "    f,score= find_highest_correlation(corr_matrix,feature)\n",
        "    corr_feature[feature] = {'feature':f, 'score':score}\n",
        "\n",
        "for feature in df_feature_analysis.columns:\n",
        "   try:\n",
        "       t = corr_feature[feature]['feature']\n",
        "       if corr_feature[t]['feature'] == feature:\n",
        "           del corr_feature[t]\n",
        "   except KeyError:\n",
        "       continue\n",
        "\n",
        "corr_feature = dict(sorted(corr_feature.items(), key=lambda item: item[1]['score'], reverse=True))\n",
        "corr_feature = {f:corr_feature[f] for f in corr_feature.keys() if corr_feature[f]['score'] >= corr_tresh }\n",
        "corr_feature\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compare_features(feature:list[Features],order_by:Features, ascending:bool=True):\n",
        "    if y_label not in feature:\n",
        "        feature.append(y_label)\n",
        "        print(feature)\n",
        "    if order_by not in feature:\n",
        "        raise ValueError('order_by must be in the feature parameter')\n",
        "    \n",
        "    if order_by == y_label:\n",
        "        raise ValueError(f'cannot order_by the {y_label}')\n",
        "    return df_train[feature].sort_values(by=order_by,axis=0,ascending=ascending)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHA8rjaajxbp"
      },
      "source": [
        "*For now we know that **is_ftp_login** and **ct_ftp_cmd** are exactly the same, so we can remove one them*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "features_to_remove=['is_ftp_login']\n",
        "#features_to_remove=['is_ftp_login','sbytes','dbytes','swin','dpkts','spkts']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYTcJk2ejxbp"
      },
      "source": [
        "##### PCA\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "nIAVH_Ljjxbp"
      },
      "outputs": [],
      "source": [
        "top_n_components =  30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['dur', 'proto', 'service', 'state', 'spkts', 'dpkts', 'sbytes',\n",
              "       'dbytes', 'rate', 'sttl', 'dttl', 'sload', 'dload', 'sloss', 'dloss',\n",
              "       'sinpkt', 'dinpkt', 'sjit', 'djit', 'swin', 'stcpb', 'dtcpb', 'dwin',\n",
              "       'tcprtt', 'synack', 'ackdat', 'smean', 'dmean', 'trans_depth',\n",
              "       'response_body_len'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feature_cov = np.dot(df_feature_analysis.transpose(), df_feature_analysis)/len(df_feature_analysis)\n",
        "eigenvalues, eigenvectors = np.linalg.eig(feature_cov)\n",
        "pca_index= np.argsort(eigenvalues)[::-1][:top_n_components]\n",
        "pca_feature = df_feature_analysis.columns[pca_index]\n",
        "pca_feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "asRL_8AVjxbp",
        "outputId": "4f416001-ff12-4166-8ded-a71eab9f3de7"
      },
      "outputs": [],
      "source": [
        "def toPCA_space(df:pd.DataFrame,pca_list,top_n_components=top_n_components):\n",
        "    pca = PCA(n_components=top_n_components)\n",
        "    pca.fit(df.values)\n",
        "    pca_data = pca.transform(df.values)\n",
        "    return pd.DataFrame(pca_data, columns=pca_list),pca.explained_variance_ratio_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_t-WrhBjxbq"
      },
      "source": [
        "### Final Preprocessing Step"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFv361vqjxbq"
      },
      "source": [
        "*Based on the various technique we decided to remove those features*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "AmhfbQrtjxbq"
      },
      "outputs": [],
      "source": [
        "features_to_ohe = list(set(features_to_ohe).difference(features_to_remove))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "Ar5oYUCHjxbv"
      },
      "outputs": [],
      "source": [
        "X_train, Y_train = separate(preprocess_final(df_train,features_to_remove=features_to_remove))\n",
        "X_test, Y_test = separate(preprocess_final(df_test,features_to_remove=features_to_remove))\n",
        "#X_train_PCA = toPCA_space(df_train.drop([y_label]),pca_feature.to_list(),)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#X_train = X_train_PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6MQ7Wx8jxbv",
        "outputId": "a43b290b-5d48-46cb-8d28-240e984e5f1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The shape of Training Set is: (175341, 41)\n",
            "The shape of Testing Set is: (82332, 41)\n"
          ]
        }
      ],
      "source": [
        "print_dataframe_shape(X_train,'Training Set')\n",
        "print_dataframe_shape(X_test,'Testing Set')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CzDrJnm6jxbv",
        "outputId": "57908459-0577-4abb-cfb6-6ccd4f35d54a"
      },
      "outputs": [],
      "source": [
        "del df_train, df_test,df_feature_analysis,corr_matrix\n",
        "collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWMufKIQjxbw"
      },
      "source": [
        "## Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "lfn9d2iSvKx4"
      },
      "outputs": [],
      "source": [
        "class LabelClass:\n",
        "\n",
        "    def __init__(self,pos_class, neg_class,pos_name,neg_name,prefered_class=None) -> None:\n",
        "        self.PositiveClass:int = pos_class\n",
        "        self.NegativeClass:int = neg_class\n",
        "        self.NegativeName:str = neg_name\n",
        "        self.PositiveName:str = pos_name\n",
        "        self.PreferedClass= self.NegativeClass if prefered_class is None else self.PositiveClass\n",
        "\n",
        "        self.answer={\n",
        "            self.PositiveClass: self.PositiveName,\n",
        "            self.NegativeClass: self.NegativeName\n",
        "        }\n",
        "    \n",
        "problem_label_class = LabelClass(0,1,'Normal','Attack')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "08muutp5jxbw"
      },
      "outputs": [],
      "source": [
        "class BinaryClassifier:\n",
        "\n",
        "    def __init__(self,label_class=problem_label_class):\n",
        "        self.X = None\n",
        "        self.Y = None\n",
        "        self.Y_Pred:list = None\n",
        "        self.Y_PredProba=[]\n",
        "        self.label_class = label_class\n",
        "\n",
        "    def fit(self):\n",
        "      ...\n",
        "\n",
        "    def predict(self): \n",
        "      ...\n",
        "\n",
        "    def _compute_analysis(self,y_test):\n",
        "        self.TP=0\n",
        "        self.TN=0\n",
        "        self.FP=0\n",
        "        self.FN=0\n",
        "\n",
        "        # Positive class = 0\n",
        "        # Negative class = 1\n",
        "\n",
        "        for truth,pred in zip(y_test,self.Y_Pred):\n",
        "            if truth ==self.label_class.NegativeClass and pred ==self.label_class.NegativeClass:\n",
        "              self.TN+=1\n",
        "            elif truth ==self.label_class.PositiveClass and pred ==self.label_class.PositiveClass:\n",
        "              self.TP+=1\n",
        "            elif truth ==self.label_class.NegativeClass and pred == self.label_class.PositiveClass:\n",
        "              self.FP+=1\n",
        "            else:\n",
        "              self.FN+=1\n",
        "        self.roc_info = roc_curve(y_test, self.Y_PredProba)\n",
        "        self.precision_recall_info = precision_recall_curve(y_test, self.Y_PredProba)\n",
        "\n",
        "    def plot_confusion_matrix(self):\n",
        "      confusion_matrix = np.array([[self.TN, self.FP], [self.FN, self.TP]])\n",
        "\n",
        "      plt.figure(figsize=(6, 4))\n",
        "      sns.heatmap(confusion_matrix, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
        "                  xticklabels=['Predicted Negative', 'Predicted Positive'],\n",
        "                  yticklabels=['Actual Negative', 'Actual Positive'])\n",
        "\n",
        "      plt.title('Confusion Matrix')\n",
        "      plt.xlabel('Predicted Labels')\n",
        "      plt.ylabel('True Labels')\n",
        "      plt.show()\n",
        "\n",
        "    def plot_roc_curve(self):\n",
        "      fpr, tpr, thresholds_roc =self.roc_info\n",
        "      plt.figure()\n",
        "      plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {auc(fpr, tpr):0.2f})')\n",
        "      plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "      plt.xlabel('False Positive Rate')\n",
        "      plt.ylabel('True Positive Rate')\n",
        "      plt.title('ROC Curve')\n",
        "      plt.legend(loc=\"lower right\")\n",
        "      plt.show()\n",
        "\n",
        "    def plot_precision_recall_curve(self):\n",
        "      precision, recall, thresholds_pr = self.precision_recall_info\n",
        "      plt.figure()\n",
        "      plt.plot(recall, precision, color='b', lw=2)\n",
        "      plt.xlabel('Recall')\n",
        "      plt.ylabel('Precision')\n",
        "      plt.title('Precision-Recall Curve')\n",
        "      plt.show()\n",
        "\n",
        "    @property\n",
        "    def accuracy(self):\n",
        "      return (self.TP + self.TN)/(self.TP + self.TN +self.FP + self.FN)\n",
        "\n",
        "    @property\n",
        "    def f1_score(self):\n",
        "      return (2*self.precision * self.recall)/(self.precision+self.recall)\n",
        "\n",
        "    @property\n",
        "    def precision(self):\n",
        "      return (self.TP)/(self.TP + self.FP)\n",
        "\n",
        "    @property\n",
        "    def recall(self):\n",
        "      return self.TP/(self.TP + self.FN)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWEyeqnKjxbw"
      },
      "source": [
        "### Decision Tree\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "class Question:\n",
        "\n",
        "    def __init__(self,feature:str,value:float,information_gain:float):\n",
        "        self.feature = feature\n",
        "        self.value = value\n",
        "        self.information_gain = information_gain\n",
        "        \n",
        "    def split(self,dataset:pd.DataFrame)->tuple[pd.DataFrame,pd.DataFrame]:\n",
        "        ...\n",
        "\n",
        "    def __repr__(self,_type):\n",
        "        return f'Is {Style.DIM}{self.feature}{Style.RESET_ALL} {Style.BRIGHT}{_type}{Style.RESET_ALL} to {Style.DIM}{self.value}{Style.RESET_ALL} ? - Gain[{self.information_gain}]'\n",
        "\n",
        "    def match(self,vector:pd.Series) -> bool:\n",
        "        ...\n",
        "        \n",
        "    def __eq__(self, other):\n",
        "        return self.information_gain == other.information_gain\n",
        "\n",
        "    def __ne__(self, other):\n",
        "        return self.information_gain != other.information_gain\n",
        "\n",
        "    def __gt__(self, other):\n",
        "        return self.information_gain > other.information_gain\n",
        "\n",
        "    def __ge__(self, other):\n",
        "        return self.information_gain >= other.information_gain\n",
        "\n",
        "class QuestionEqual(Question):\n",
        "    def split(self, dataset):\n",
        "       return dataset[dataset[self.feature] == self.value], dataset[dataset[self.feature] != self.value]\n",
        "    \n",
        "    def match(self,vector):\n",
        "        return vector[self.feature] == self.value\n",
        "    \n",
        "    def __repr__(self):\n",
        "        return super().__repr__('equal')\n",
        "    \n",
        "\n",
        "class QuestionThresh(Question):\n",
        "    def split(self, dataset):\n",
        "       return dataset[dataset[self.feature] >= self.value], dataset[dataset[self.feature] < self.value]\n",
        "    \n",
        "    def match(self,vector):\n",
        "        return vector[self.feature] >= self.value\n",
        "    \n",
        "    def __repr__(self):\n",
        "        return super().__repr__('greater or equal')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6GtfGUvjxbw"
      },
      "source": [
        "##### Node class\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "sYeMbfebjxbw"
      },
      "outputs": [],
      "source": [
        "class Node:\n",
        "    ...\n",
        "\n",
        "class TreeNode(Node):\n",
        "    def __init__(self,question:Question,left:Node,right:Node):\n",
        "        self.question = question\n",
        "        \"\"\"\n",
        "        Satisfy the match\n",
        "        \"\"\"\n",
        "        self.left=left\n",
        "        \"\"\"\n",
        "        Dissatisfy the match\n",
        "        \"\"\"\n",
        "        self.right = right\n",
        "    \n",
        "    def match(self,value) -> bool:\n",
        "        return self.question.match(value)\n",
        "    \n",
        "    def __repr__(self):\n",
        "        return repr(self.question)\n",
        "    \n",
        "\n",
        "class LeafNode(Node):\n",
        "\n",
        "    def __init__(self,probabilities,label_class:LabelClass):\n",
        "        self.proba = probabilities\n",
        "        self.label_class = label_class\n",
        "        self.answer:Literal[0,1,None] = self._compute_answer()\n",
        "        \n",
        "    def _compute_answer(self):\n",
        "        label_0 = self.proba[0]\n",
        "        label_1 = self.proba[1]\n",
        "\n",
        "        if label_0 == label_1:\n",
        "            return self.label_class.PreferedClass\n",
        "        \n",
        "        return 1 if label_1 > label_0 else 0\n",
        "            \n",
        "    @property\n",
        "    def answer_proba(self):\n",
        "        return self.proba[self.answer]\n",
        "\n",
        "    def repr(self):\n",
        "        return f'It is {Style.DIM}{self.label_class.answer[self.answer]}{Style.RESET_ALL} with a probability of {self.answer_proba:.4f} %'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3huK6Trejxbx"
      },
      "source": [
        "##### DecisionTree class\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train, x_val, y_train, y_val = train_test_split(X_train, Y_train, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "7cX4r-vujxbx"
      },
      "outputs": [],
      "source": [
        "ImpurityType=Literal['gini_index','entropy']\n",
        "\n",
        "class DecisionTreeClassifier(BinaryClassifier):\n",
        "  \n",
        "    def __init__(self,max_height:int,min_information_gain:float,min_sample:int,impurity:ImpurityType='entropy',label_class=problem_label_class):\n",
        "      super().__init__(label_class)\n",
        "      self.max_height = max_height\n",
        "      self.min_information_gain = min_information_gain\n",
        "      self.min_sample = min_sample\n",
        "      self.impurity = self._gini_impurity if impurity == 'gini_index' else self._entropy\n",
        "      self.root: TreeNode = None\n",
        "\n",
        "    def fit(self,x_train:pd.DataFrame,y_train:pd.DataFrame):\n",
        "      self.X = x_train\n",
        "      self.Y = y_train\n",
        "      self.root_dataset = pd.concat([self.X,self.Y],axis=1)\n",
        "       \n",
        "    def train(self,x_val,y_val):\n",
        "      self.root =self._build_tree(self.root_dataset)\n",
        "      self.predict(x_val,y_val)\n",
        "\n",
        "    def repr(self):\n",
        "      return f'DecisionTree(Max_Depth={self.max_height},Min_Inf_Gain={self.min_information_gain},Min_Sample={self.min_sample},Impurity={self.impurity})'\n",
        "    \n",
        "    def predict(self,x_to_test,y_to_test):\n",
        "      self.Y_Pred = self._predict(x_to_test)\n",
        "      self._compute_analysis(y_to_test)\n",
        "\n",
        "    def _predict(self,x_to_test:pd.DataFrame):\n",
        "      return x_to_test.drop([y_label]).apply(self._traverse_tree,axis=0).values\n",
        "      \n",
        "    def _entropy(self,labels:np.ndarray):\n",
        "      probabilities = self._compute_target_probabilities(labels)\n",
        "      return -np.sum(probabilities * np.log2(probabilities))\n",
        "\n",
        "    def _gini_impurity(self,labels:np.ndarray):\n",
        "      probabilities = self._compute_target_probabilities(labels)\n",
        "      return (1 - np.sum(probabilities**2))\n",
        "\n",
        "    def _compute_target_probabilities(self,labels):\n",
        "      _, counts = np.unique(labels, return_counts=True)\n",
        "      return counts / len(labels)\n",
        "\n",
        "    def _information_gain(self,current_information_gain:float,mean_impurity:float):\n",
        "      return current_information_gain - mean_impurity\n",
        "\n",
        "    def _build_tree(self,dataset:pd.DataFrame,current_depth:int =0) ->TreeNode | LeafNode:\n",
        "        parent_gain = self.impurity(dataset)\n",
        "        current_n = len(dataset)\n",
        "\n",
        "        if current_depth >= self.max_height or current_n < self.min_sample or parent_gain < self.min_information_gain:\n",
        "          proba= self._compute_target_probabilities(dataset[y_label].values)\n",
        "          return LeafNode(proba,self.label_class)\n",
        "        \n",
        "        best_question=self._find_best_split(dataset,parent_gain)\n",
        "\n",
        "        left_dataset,right_dataset =self._split_dataset(dataset,best_question)\n",
        "        left_child = self._build_tree(left_dataset,current_depth+1)\n",
        "        right_child = self._build_tree(right_dataset,current_depth+1)\n",
        "\n",
        "        return TreeNode(best_question,left_child,right_child)\n",
        "\n",
        "    def _traverse_tree(self,x_vector:pd.Series):\n",
        "      current_node:LeafNode | TreeNode = self.root\n",
        "      while isinstance(current_node,TreeNode):\n",
        "          answer = current_node.match(x_vector)\n",
        "          current_node = current_node.left if answer else current_node.right\n",
        "      \n",
        "      self.Y_PredProba.append(current_node.proba)\n",
        "      return current_node.answer\n",
        "\n",
        "    def print_tree(self,):\n",
        "        self._print_tree(self.root,0)\n",
        "\n",
        "    def _print_tree(self,node:Node| TreeNode, depth,answer =None):\n",
        "        print('' if answer is None else answer,' '*depth,node)\n",
        "        if type(node) is TreeNode:\n",
        "          self._print_tree(node.left,depth+1,'YES... ')\n",
        "          self._print_tree(node.right,depth+1,'NO... ')\n",
        "\n",
        "    def _split_dataset(self,dataset:pd.DataFrame,question:Question):\n",
        "      return question.split(dataset)\n",
        "\n",
        "    def _find_best_split(self,dataset:pd.DataFrame,current_gain:float)->Question:\n",
        "      \n",
        "      best_question = Question(None,None,float('inf'))\n",
        "      for feature in dataset.columns:\n",
        "        if feature in features_to_ohe: \n",
        "           for values in dataset[feature].unique():\n",
        "            best_question = self._compute_best_question(dataset, current_gain,feature, values,best_question,QuestionEqual)            \n",
        "        else:\n",
        "          val_unique_mean = dataset[feature].unique().mean()\n",
        "          val_mean = dataset[feature].mean()\n",
        "          val_median = dataset[feature].median()\n",
        "\n",
        "          for values in [val_unique_mean,val_mean,val_median]:\n",
        "            best_question = self._compute_best_question(dataset, current_gain,feature, values,best_question,QuestionThresh)\n",
        "\n",
        "      return Question\n",
        "    \n",
        "    def _compute_best_question(self, dataset:pd.DataFrame, current_gain:float,feature:str, values:float,best_question:Question,Q_type:type) ->Question:\n",
        "        N = len(dataset)\n",
        "        if Q_type== QuestionEqual:\n",
        "          y_satisfaction,y_dissatisfaction  = dataset[dataset[feature]== values].label.values,dataset[dataset[feature]!= values].label.values\n",
        "\n",
        "        else:\n",
        "          y_satisfaction, y_dissatisfaction = dataset[dataset[feature] >= values].label.values, dataset[dataset[feature] < values].label.values\n",
        "\n",
        "        mean_impurity = (len(y_dissatisfaction)/N)*self.impurity(y_dissatisfaction) + (len(y_satisfaction)/N)*self.impurity(y_satisfaction)\n",
        "        info_gain = self._information_gain(current_gain,mean_impurity)\n",
        "        print(Q_type)\n",
        "        question =  Q_type(feature,values,info_gain)\n",
        "\n",
        "        return question if question > best_question else best_question\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2SA5OPrjxbx"
      },
      "source": [
        "### K-Nearest Neighbors\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "j8Ef0Fwajxbx"
      },
      "outputs": [],
      "source": [
        "class KNNClassifier(BinaryClassifier):\n",
        "\n",
        "    def __init__(self,ohe_feature:list[str] ,max_k:int=None,N_batch=100) -> None:\n",
        "        super().__init__()\n",
        "        if max_k is not None:\n",
        "          self.K = self._to_odd_number( max_k-1)\n",
        "        else:\n",
        "          self.K = self._to_odd_number(round(max_k**0.5))\n",
        "        self.N_batch = N_batch\n",
        "        self.ohe_features =  ohe_feature\n",
        "        self.ohe_func = cp.vectorize(self._to_one_hot_encoding)\n",
        "      \n",
        "\n",
        "    def fit(self,X_train:pd.DataFrame,Y_train:pd.DataFrame):\n",
        "        self.X  = X_train\n",
        "        self.Y = Y_train\n",
        "        self.x_num, self.x_ohe = self._split(X_train)\n",
        "\n",
        "    def _to_odd_number(self, val):\n",
        "        return val-1 if val%2 == 0 else val\n",
        "\n",
        "    def _split(self,df:pd.DataFrame):\n",
        "        return df.drop(self.ohe_features),df[self.ohe_features]\n",
        "\n",
        "    def predict(self,x_test,y_test):\n",
        "      dataframes_indices = self._predict(self._split(x_test))\n",
        "      df_distances = pd.DataFrame(pd.concat(dataframes_indices).apply(self._prevote,axis=1))\n",
        "      self.Y_Pred = df_distances.label.apply(self._vote_majority).values\n",
        "      del dataframes_indices, df_distances\n",
        "      collect()\n",
        "      self._compute_analysis(y_test)\n",
        "\n",
        "    def _prevote(row):\n",
        "      return [int(Y_train[i]) for i in  row.tolist()]\n",
        "\n",
        "    def _predict(self,test:tuple):\n",
        "      test_x_num, test_x_ohe = test\n",
        "      N =len(test_x_num)\n",
        "      fold_size =  N / self.N_batch\n",
        "      dataframes_indices = []\n",
        "      #sleep(100)\n",
        "      for i in tqdm(range(self.N_batch)):\n",
        "        cp.get_default_memory_pool().free_all_blocks()\n",
        "        a,b= round(fold_size*i),round(fold_size*(i+1))\n",
        "        num,ohe = test_x_num[a:b],test_x_ohe[a:b]\n",
        "        temp = self._compute_distance(num,self.x_num) + self.ohe_func(self._compute_distance(ohe,self.x_ohe))\n",
        "        top_500_indices = cp.argsort(temp, axis=1)[:, :self.K] # TODO check give the label now\n",
        "        dataframes_indices.append(pd.DataFrame(top_500_indices.get()))\n",
        "        del temp, top_500_indices\n",
        "        collect()\n",
        "        #print(f'\\nCalculating distance of the max k in Batch: {i+1}/{self.N_batch}')\n",
        "        sleep(0.1)\n",
        "      return dataframes_indices\n",
        "\n",
        "    def _to_one_hot_encoding(x):\n",
        "      return 0 if x == 0 else 1\n",
        "\n",
        "    def _compute_distance(a,b):\n",
        "      A = a.to_numpy(dtype='float32')\n",
        "      B = b.to_numpy(dtype='float32')\n",
        "      A = cp.asarray(A)\n",
        "      B = cp.asarray(B)\n",
        "      A_sq_norms = cp.sum(A ** 2, axis=1).reshape(-1, 1)  # Shape (n, 1)\n",
        "      B_sq_norms = cp.sum(B ** 2, axis=1).reshape(1, -1)  # Shape (1, m)\n",
        "\n",
        "      dot_product = cp.dot(A, B.T)  # Shape (n, m)\n",
        "      euclidean_distances = A_sq_norms + B_sq_norms - 2 * dot_product\n",
        "      del A_sq_norms,B_sq_norms, dot_product, A,B\n",
        "      collect()\n",
        "      return euclidean_distances\n",
        "\n",
        "    def _vote_majority(self,label_vectors):\n",
        "      n = len(label_vectors)\n",
        "      sum_one = label_vectors.count(1)\n",
        "      sum_zero =n-sum_one\n",
        "      self.Y_PredProba.append(sum_zero/n)\n",
        "      return 1 if sum_one > len(label_vectors)-sum_one else 0\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionEqual'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n",
            "<class '__main__.QuestionThresh'>\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "Question.split() missing 1 required positional argument: 'dataset'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[50], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m test \u001b[38;5;241m=\u001b[39m DecisionTreeClassifier(\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m.2\u001b[39m,\u001b[38;5;241m500\u001b[39m)\n\u001b[0;32m      2\u001b[0m test\u001b[38;5;241m.\u001b[39mfit(x_train,y_train)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mtest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m test\u001b[38;5;241m.\u001b[39maccuracy\n",
            "Cell \u001b[1;32mIn[49], line 19\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.train\u001b[1;34m(self, x_val, y_val)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m,x_val,y_val):\n\u001b[1;32m---> 19\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot \u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(x_val,y_val)\n",
            "Cell \u001b[1;32mIn[49], line 57\u001b[0m, in \u001b[0;36mDecisionTreeClassifier._build_tree\u001b[1;34m(self, dataset, current_depth)\u001b[0m\n\u001b[0;32m     53\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m LeafNode(proba,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_class)\n\u001b[0;32m     55\u001b[0m best_question\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_find_best_split(dataset,parent_gain)\n\u001b[1;32m---> 57\u001b[0m left_dataset,right_dataset \u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_split_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbest_question\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m left_child \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_tree(left_dataset,current_depth\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     59\u001b[0m right_child \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_tree(right_dataset,current_depth\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
            "Cell \u001b[1;32mIn[49], line 82\u001b[0m, in \u001b[0;36mDecisionTreeClassifier._split_dataset\u001b[1;34m(self, dataset, question)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_split_dataset\u001b[39m(\u001b[38;5;28mself\u001b[39m,dataset:pd\u001b[38;5;241m.\u001b[39mDataFrame,question:Question):\n\u001b[1;32m---> 82\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mquestion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mTypeError\u001b[0m: Question.split() missing 1 required positional argument: 'dataset'"
          ]
        }
      ],
      "source": [
        "test = DecisionTreeClassifier(8,.2,500)\n",
        "test.fit(x_train,y_train)\n",
        "test.train(x_val,y_val)\n",
        "test.accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HibQqFnsjxbx"
      },
      "source": [
        "## Testing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_model(model:BinaryClassifier):\n",
        "    ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVyEGKexjxby"
      },
      "source": [
        "## Conclusion\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "INF6953QE",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
